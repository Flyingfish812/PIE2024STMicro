{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'pyarrow' has no attribute '__version__'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# !pip install numpy=1.26.4 pandas=2.2.2 -y\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\__init__.py:26\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m _hard_dependencies, _dependency, _missing_dependencies\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     25\u001b[0m     \u001b[38;5;66;03m# numpy compat\u001b[39;00m\n\u001b[1;32m---> 26\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     27\u001b[0m         is_numpy_dev \u001b[38;5;28;01mas\u001b[39;00m _is_numpy_dev,  \u001b[38;5;66;03m# pyright: ignore[reportUnusedImport] # noqa: F401\u001b[39;00m\n\u001b[0;32m     28\u001b[0m     )\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m _err:  \u001b[38;5;66;03m# pragma: no cover\u001b[39;00m\n\u001b[0;32m     30\u001b[0m     _module \u001b[38;5;241m=\u001b[39m _err\u001b[38;5;241m.\u001b[39mname\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\compat\\__init__.py:27\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompressors\u001b[39;00m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m is_numpy_dev\n\u001b[1;32m---> 27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyarrow\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     28\u001b[0m     pa_version_under10p1,\n\u001b[0;32m     29\u001b[0m     pa_version_under11p0,\n\u001b[0;32m     30\u001b[0m     pa_version_under13p0,\n\u001b[0;32m     31\u001b[0m     pa_version_under14p0,\n\u001b[0;32m     32\u001b[0m     pa_version_under14p1,\n\u001b[0;32m     33\u001b[0m     pa_version_under16p0,\n\u001b[0;32m     34\u001b[0m )\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m TYPE_CHECKING:\n\u001b[0;32m     37\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_typing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m F\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\compat\\pyarrow.py:10\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpyarrow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpa\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m     _palv \u001b[38;5;241m=\u001b[39m Version(Version(pa\u001b[38;5;241m.\u001b[39m__version__)\u001b[38;5;241m.\u001b[39mbase_version)\n\u001b[0;32m     11\u001b[0m     pa_version_under10p1 \u001b[38;5;241m=\u001b[39m _palv \u001b[38;5;241m<\u001b[39m Version(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m10.0.1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     12\u001b[0m     pa_version_under11p0 \u001b[38;5;241m=\u001b[39m _palv \u001b[38;5;241m<\u001b[39m Version(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m11.0.0\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'pyarrow' has no attribute '__version__'"
     ]
    }
   ],
   "source": [
    "\n",
    "# !pip install numpy=1.26.4 pandas=2.2.2 -y\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import MinMaxScaler ,  StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import GridSearchCV,train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Obtaining dependency information for tensorflow from https://files.pythonhosted.org/packages/3c/e3/e868f1d5951047f950d2ba1e04a765a3328a51f06996b67976d6102f8227/tensorflow-2.19.0-cp311-cp311-win_amd64.whl.metadata\n",
      "  Using cached tensorflow-2.19.0-cp311-cp311-win_amd64.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\nagui\\anaconda3\\lib\\site-packages (from tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\nagui\\anaconda3\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\nagui\\anaconda3\\lib\\site-packages (from tensorflow) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\nagui\\anaconda3\\lib\\site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\nagui\\anaconda3\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\nagui\\anaconda3\\lib\\site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\nagui\\anaconda3\\lib\\site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\nagui\\anaconda3\\lib\\site-packages (from tensorflow) (24.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\users\\nagui\\anaconda3\\lib\\site-packages (from tensorflow) (5.29.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\nagui\\anaconda3\\lib\\site-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\nagui\\anaconda3\\lib\\site-packages (from tensorflow) (68.0.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\nagui\\anaconda3\\lib\\site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\nagui\\anaconda3\\lib\\site-packages (from tensorflow) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\nagui\\anaconda3\\lib\\site-packages (from tensorflow) (4.12.2)\n",
      "Collecting wrapt>=1.11.0 (from tensorflow)\n",
      "  Obtaining dependency information for wrapt>=1.11.0 from https://files.pythonhosted.org/packages/47/f8/fb1773491a253cbc123c5d5dc15c86041f746ed30416535f2a8df1f4a392/wrapt-1.17.2-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading wrapt-1.17.2-cp311-cp311-win_amd64.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\nagui\\anaconda3\\lib\\site-packages (from tensorflow) (1.71.0)\n",
      "Requirement already satisfied: tensorboard~=2.19.0 in c:\\users\\nagui\\anaconda3\\lib\\site-packages (from tensorflow) (2.19.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in c:\\users\\nagui\\anaconda3\\lib\\site-packages (from tensorflow) (3.9.0)\n",
      "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in c:\\users\\nagui\\anaconda3\\lib\\site-packages (from tensorflow) (1.26.4)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\nagui\\anaconda3\\lib\\site-packages (from tensorflow) (3.13.0)\n",
      "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in c:\\users\\nagui\\anaconda3\\lib\\site-packages (from tensorflow) (0.5.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\nagui\\anaconda3\\lib\\site-packages (from tensorflow) (0.31.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\nagui\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.38.4)\n",
      "Requirement already satisfied: rich in c:\\users\\nagui\\anaconda3\\lib\\site-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
      "Requirement already satisfied: namex in c:\\users\\nagui\\anaconda3\\lib\\site-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in c:\\users\\nagui\\anaconda3\\lib\\site-packages (from keras>=3.5.0->tensorflow) (0.14.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\nagui\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\nagui\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\nagui\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\nagui\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2025.1.31)\n",
      "Collecting markdown>=2.6.8 (from tensorboard~=2.19.0->tensorflow)\n",
      "  Obtaining dependency information for markdown>=2.6.8 from https://files.pythonhosted.org/packages/3f/08/83871f3c50fc983b88547c196d11cf8c3340e37c32d2e9d6152abe2c61f7/Markdown-3.7-py3-none-any.whl.metadata\n",
      "  Downloading Markdown-3.7-py3-none-any.whl.metadata (7.0 kB)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\nagui\\anaconda3\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard~=2.19.0->tensorflow)\n",
      "  Obtaining dependency information for werkzeug>=1.0.1 from https://files.pythonhosted.org/packages/52/24/ab44c871b0f07f491e5d2ad12c9bd7358e527510618cb1b803a88e986db1/werkzeug-3.1.3-py3-none-any.whl.metadata\n",
      "  Downloading werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\nagui\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.2)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich->keras>=3.5.0->tensorflow)\n",
      "  Obtaining dependency information for markdown-it-py>=2.2.0 from https://files.pythonhosted.org/packages/42/d7/1ec15b46af6af88f19b8e5ffea08fa375d433c998b8a7639e76935c14f1f/markdown_it_py-3.0.0-py3-none-any.whl.metadata\n",
      "  Downloading markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\nagui\\anaconda3\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow) (2.15.1)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow)\n",
      "  Obtaining dependency information for mdurl~=0.1 from https://files.pythonhosted.org/packages/b3/38/89ba8ad64ae25be8de66a6d463314cf1eb366222074cfda9ee839c56a4b4/mdurl-0.1.2-py3-none-any.whl.metadata\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Using cached tensorflow-2.19.0-cp311-cp311-win_amd64.whl (375.9 MB)\n",
      "Downloading wrapt-1.17.2-cp311-cp311-win_amd64.whl (38 kB)\n",
      "Downloading Markdown-3.7-py3-none-any.whl (106 kB)\n",
      "   ---------------------------------------- 0.0/106.3 kB ? eta -:--:--\n",
      "   ----------------------- ---------------- 61.4/106.3 kB 1.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 106.3/106.3 kB 1.6 MB/s eta 0:00:00\n",
      "Downloading werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
      "   ---------------------------------------- 0.0/224.5 kB ? eta -:--:--\n",
      "   ---------- ----------------------------- 61.4/224.5 kB 3.4 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 143.4/224.5 kB 2.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 224.5/224.5 kB 2.0 MB/s eta 0:00:00\n",
      "Downloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "   ---------------------------------------- 0.0/87.5 kB ? eta -:--:--\n",
      "   -------------------------------- ------- 71.7/87.5 kB 1.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 87.5/87.5 kB 2.4 MB/s eta 0:00:00\n",
      "Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Installing collected packages: wrapt, werkzeug, mdurl, markdown, markdown-it-py, tensorflow\n",
      "Successfully installed markdown-3.7 markdown-it-py-3.0.0 mdurl-0.1.2 tensorflow-2.19.0 werkzeug-3.1.3 wrapt-1.17.2\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feat = pd.read_csv(r'C:\\Users\\NAGUI\\Downloads\\Projet PIE - Encrypted\\Projet PIE - Encrypted\\encoded data\\opamps-features.csv')\n",
    "df_ref = pd.read_csv(r'C:\\Users\\NAGUI\\Downloads\\Projet PIE - Encrypted\\Projet PIE - Encrypted\\encoded data\\opamps-xref.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prétraitement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = [\"Supplier_Package\",\"MANUFACTURER\"]\n",
    "numerical_columns = [\"Maximum Input Offset Voltage\",\"Maximum Single Supply Voltage\",\"Minimum Single Supply Voltage\",\"Number of Channels per Chip\",\"Typical Gain Bandwidth Product\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalisation des données numériques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import helper_functions.preprocess as pp\n",
    "\n",
    "df_feat_scaled , scaler = pp.scale(df_feat,numerical_columns)\n",
    "df = pp.merge_datasets(df_feat_scaled,df_ref)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conversion de la Cross Reference Type en numerique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_means = {'A': 0.95, 'B': 0.8, 'C': 0.65, 'D': 0.5}\n",
    "base_std = {'A': 0.025 / 3, 'B': 0.025 / 2.5, 'C': 0.025 / 2, 'D': 0.025 / 1.5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pp.generate_closeness(df,base_means,base_std,n_std=3)\n",
    "sns.kdeplot(data=df, x='Closeness', hue='Cross Reference Type', fill=True, common_norm=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df[['MPN', 'MANUFACTURER',\n",
    "       'Maximum Input Offset Voltage', 'Maximum Single Supply Voltage',\n",
    "       'Minimum Single Supply Voltage', 'Number of Channels per Chip',\n",
    "       'Supplier_Package', 'Typical Gain Bandwidth Product']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Supplier_Package'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.drop_duplicates(subset=['MPN', 'MANUFACTURER'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(nrow:=len(df))\n",
    "package_counts = df.groupby('Supplier_Package').size()\n",
    "print(package_frequencies := package_counts/nrow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract original numerical columns and Supplier_Package\n",
    "original_numerical = ['Maximum Input Offset Voltage', 'Maximum Single Supply Voltage',\n",
    "                      'Minimum Single Supply Voltage', 'Number of Channels per Chip',\n",
    "                      'Typical Gain Bandwidth Product']\n",
    "X_numerical = df[original_numerical].values\n",
    "y = df['MANUFACTURER'].values\n",
    "\n",
    "\n",
    "# Create frequency-weighted one-hot encoding for Supplier_Package\n",
    "package_freq_df = pd.get_dummies(df['Supplier_Package']).astype('float')\n",
    "for col in package_freq_df.columns:\n",
    "    package_freq_df[col] = package_freq_df[col] * package_frequencies[col]\n",
    "X_package_freq = package_freq_df.values\n",
    "\n",
    "# Combine unchanged numerical features with frequency-weighted package features\n",
    "X = np.hstack((X_numerical, X_package_freq))\n",
    "numerical_columns = original_numerical + package_freq_df.columns.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Debug: Check the frequency-weighted matrix\n",
    "print(\"X_package_freq sample:\")\n",
    "print(X_package_freq[:5])  # Print first 5 rows to inspect\n",
    "print(f\"X_package_freq min: {X_package_freq.min()}, max: {X_package_freq.max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "from sklearn.metrics import silhouette_score\n",
    "import itertools\n",
    "from sklearn.decomposition import NMF\n",
    "\n",
    "# Assuming your preprocessed df is already loaded from the notebook\n",
    "# If not, you would need to run the preprocessing steps first\n",
    "\n",
    "# Define the hyperparameter search space\n",
    "param_grid = {\n",
    "    'perplexity': [30, 50, 70],         \n",
    "    'learning_rate': [100, 200, 'auto'], \n",
    "    'n_iter': [1000, 2000],             \n",
    "    'early_exaggeration': [12.0]        \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2D t-SNE Optimization Function\n",
    "\n",
    "This function performs hyperparameter optimization for 2D t-SNE projection:\n",
    "- Takes numerical features (X) and manufacturer labels (y) as input\n",
    "- Performs grid search over the reduced parameter space (~18 combinations)\n",
    "- Evaluates each combination using silhouette score\n",
    "- Returns the best model, parameters, and score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_tsne_2d(X, y, param_grid, random_state=42):\n",
    "    \"\"\"\n",
    "    Optimize TSNE for 2D projection\n",
    "    X: numerical features\n",
    "    y: manufacturer labels\n",
    "    \"\"\"\n",
    "    best_score = -1\n",
    "    best_params = None\n",
    "    best_model = None\n",
    "    \n",
    "    # Generate all parameter combinations\n",
    "    param_combinations = list(itertools.product(\n",
    "        param_grid['perplexity'],\n",
    "        param_grid['learning_rate'],\n",
    "        param_grid['n_iter'],\n",
    "        param_grid['early_exaggeration']\n",
    "    ))\n",
    "    \n",
    "    for params in param_combinations:\n",
    "        perplexity, learning_rate, n_iter, early_exaggeration = params\n",
    "        \n",
    "        try:\n",
    "            # Create and fit TSNE model\n",
    "            tsne = TSNE(\n",
    "                n_components=2,\n",
    "                perplexity=perplexity,\n",
    "                learning_rate=learning_rate,\n",
    "                n_iter=n_iter,\n",
    "                early_exaggeration=early_exaggeration,\n",
    "                random_state=random_state,\n",
    "                n_jobs=-1\n",
    "            )\n",
    "            \n",
    "            # Transform the data\n",
    "            X_transformed = tsne.fit_transform(X)\n",
    "            \n",
    "            # Calculate silhouette score\n",
    "            score = silhouette_score(X_transformed, y)\n",
    "            \n",
    "            # Update best parameters if current score is better\n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                best_params = {\n",
    "                    'perplexity': perplexity,\n",
    "                    'learning_rate': learning_rate,\n",
    "                    'n_iter': n_iter,\n",
    "                    'early_exaggeration': early_exaggeration\n",
    "                }\n",
    "                best_model = tsne\n",
    "                \n",
    "            print(f\"2D - Params: {params}, Silhouette Score: {score:.4f}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"2D - Error with params {params}: {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    return best_model, best_params, best_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3D t-SNE Optimization Function\n",
    "\n",
    "This function performs hyperparameter optimization for 3D t-SNE projection:\n",
    "- Similar to the 2D version but projects to 3 dimensions\n",
    "- Uses the same reduced parameter space (~18 combinations)\n",
    "- Evaluates using silhouette score with MANUFACTURER as reference\n",
    "- Returns the best model, parameters, and score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_tsne_3d(X, y, param_grid, random_state=42):\n",
    "    \"\"\"\n",
    "    Optimize TSNE for 3D projection\n",
    "    X: numerical features\n",
    "    y: manufacturer labels\n",
    "    \"\"\"\n",
    "    best_score = -1\n",
    "    best_params = None\n",
    "    best_model = None\n",
    "    \n",
    "    # Generate all parameter combinations\n",
    "    param_combinations = list(itertools.product(\n",
    "        param_grid['perplexity'],\n",
    "        param_grid['learning_rate'],\n",
    "        param_grid['n_iter'],\n",
    "        param_grid['early_exaggeration']\n",
    "    ))\n",
    "    \n",
    "    for params in param_combinations:\n",
    "        perplexity, learning_rate, n_iter, early_exaggeration = params\n",
    "        \n",
    "        try:\n",
    "            # Create and fit TSNE model\n",
    "            tsne = TSNE(\n",
    "                n_components=3,\n",
    "                perplexity=perplexity,\n",
    "                learning_rate=learning_rate,\n",
    "                n_iter=n_iter,\n",
    "                early_exaggeration=early_exaggeration,\n",
    "                random_state=random_state,\n",
    "                n_jobs=-1\n",
    "            )\n",
    "            \n",
    "            # Transform the data\n",
    "            X_transformed = tsne.fit_transform(X)\n",
    "            \n",
    "            # Calculate silhouette score\n",
    "            score = silhouette_score(X_transformed, y)\n",
    "            \n",
    "            # Update best parameters if current score is better\n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                best_params = {\n",
    "                    'perplexity': perplexity,\n",
    "                    'learning_rate': learning_rate,\n",
    "                    'n_iter': n_iter,\n",
    "                    'early_exaggeration': early_exaggeration\n",
    "                }\n",
    "                best_model = tsne\n",
    "                \n",
    "            print(f\"3D - Params: {params}, Silhouette Score: {score:.4f}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"3D - Error with params {params}: {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    return best_model, best_params, best_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation and Optimization Execution\n",
    "\n",
    "This section:\n",
    "- Prepares the numerical features and labels from the preprocessed DataFrame\n",
    "- Executes the optimization for both 2D and 3D projections with reduced grid\n",
    "- Displays the best results for each dimensionality\n",
    "- Expected to run much faster with only 18 combinations per dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine unchanged numerical features with frequency-weighted package features\n",
    "X = np.hstack((X_numerical, X_package_freq))\n",
    "y = df['MANUFACTURER'].values\n",
    "\n",
    "\n",
    "\n",
    "# Shift to non-negative for NMF (add min value if negative)\n",
    "X_shifted = X - X.min() if X.min() < 0 else X\n",
    "\n",
    "# Apply NMF to reduce dimensions\n",
    "nmf = NMF(n_components=10, random_state=42, init='nndsvd', max_iter=10000)  # 10000 components as a starting point\n",
    "X_nmf = nmf.fit_transform(X_shifted)\n",
    "\n",
    "# Optimize for 2D\n",
    "print(\"Optimizing 2D t-SNE with NMF-reduced scaled features...\")\n",
    "best_model_2d, best_params_2d, best_score_2d = optimize_tsne_2d(X_nmf, y, param_grid)\n",
    "print(\"\\nBest 2D Results:\")\n",
    "print(f\"Best Parameters: {best_params_2d}\")\n",
    "print(f\"Best Silhouette Score: {best_score_2d:.4f}\")\n",
    "\n",
    "# Optimize for 3D\n",
    "print(\"\\nOptimizing 3D t-SNE with NMF-reduced scaled features...\")\n",
    "best_model_3d, best_params_3d, best_score_3d = optimize_tsne_3d(X_nmf, y, param_grid)\n",
    "print(\"\\nBest 3D Results:\")\n",
    "print(f\"Best Parameters: {best_params_3d}\")\n",
    "print(f\"Best Silhouette Score: {best_score_3d:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization of Results\n",
    "\n",
    "This section creates visualizations of the best t-SNE projections:\n",
    "- 2D scatter plot showing manufacturer clusters\n",
    "- 3D scatter plot showing manufacturer clusters\n",
    "- Both colored by MANUFACTURER with silhouette scores in titles\n",
    "- Uses the best models found from the grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization of the best results\n",
    "# 2D Visualization\n",
    "X_2d = best_model_2d.fit_transform(X_nmf)\n",
    "plt.figure(figsize=(10, 8))\n",
    "scatter = plt.scatter(X_2d[:, 0], X_2d[:, 1], c=pd.factorize(y)[0], cmap='viridis')\n",
    "plt.colorbar(scatter, label='MANUFACTURER')\n",
    "plt.title(f'2D t-SNE (Silhouette Score: {best_score_2d:.4f})')\n",
    "plt.xlabel('t-SNE Component 1')\n",
    "plt.ylabel('t-SNE Component 2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3D Visualization\n",
    "X_3d = best_model_3d.fit_transform(X_nmf)\n",
    "fig = plt.figure(figsize=(10, 8))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "scatter = ax.scatter(X_3d[:, 0], X_3d[:, 1], X_3d[:, 2], c=pd.factorize(y)[0], cmap='viridis')\n",
    "plt.colorbar(scatter, label='MANUFACTURER')\n",
    "ax.set_title(f'3D t-SNE (Silhouette Score: {best_score_3d:.4f})')\n",
    "ax.set_xlabel('t-SNE Component 1')\n",
    "ax.set_ylabel('t-SNE Component 2')\n",
    "ax.set_zlabel('t-SNE Component 3')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import time\n",
    "\n",
    "# Path to your Anaconda site-packages\n",
    "site_packages = r\"C:\\Users\\NAGUI\\anaconda3\\Lib\\site-packages\"\n",
    "tf_dir = os.path.join(site_packages, \"tensorflow\")\n",
    "\n",
    "if os.path.exists(tf_dir):\n",
    "    print(f\"TensorFlow directory exists at {tf_dir}\")\n",
    "    print(f\"Last modified: {time.ctime(os.path.getmtime(tf_dir))}\")\n",
    "    print(\"Checking if it's still being modified...\")\n",
    "    initial_time = os.path.getmtime(tf_dir)\n",
    "    time.sleep(5)  # Wait 5 seconds\n",
    "    new_time = os.path.getmtime(tf_dir)\n",
    "    if new_time > initial_time:\n",
    "        print(\"Directory is being modified—installation likely in progress.\")\n",
    "    else:\n",
    "        print(\"No recent changes—installation might be done or stalled.\")\n",
    "else:\n",
    "    print(\"TensorFlow directory not found—installation hasn’t started or failed.\")\n",
    "\n",
    "import os\n",
    "\n",
    "# Check pip cache for TensorFlow downloads\n",
    "cache_dir = os.path.expanduser(\"~\\\\AppData\\\\Local\\\\pip\\\\cache\")\n",
    "if os.path.exists(cache_dir):\n",
    "    for root, dirs, files in os.walk(cache_dir):\n",
    "        for file in files:\n",
    "            if \"tensorflow\" in file.lower():\n",
    "                file_path = os.path.join(root, file)\n",
    "                print(f\"Found TensorFlow file: {file_path}\")\n",
    "                print(f\"Size: {os.path.getsize(file_path) / (1024 * 1024):.2f} MB\")\n",
    "                print(f\"Last modified: {time.ctime(os.path.getmtime(file_path))}\")\n",
    "else:\n",
    "    print(\"Pip cache not found or empty.\")\n",
    "\n",
    "# Check if pip is still downloading\n",
    "print(\"\\nRunning processes:\")\n",
    "!tasklist | findstr \"pip\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
