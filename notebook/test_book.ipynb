{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ciallo STM Group!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Required libraries:\n",
    "- pandas\n",
    "- numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def analyze_csv_structure(file):\n",
    "    df = pd.read_csv(file)\n",
    "    \n",
    "    # Row numbers\n",
    "    print(f\"Total Rows in the Table: {len(df)}\\n\")\n",
    "    \n",
    "    # Columns and types\n",
    "    print(\"Column Names and Data Types:\")\n",
    "    for column, dtype in df.dtypes.items():\n",
    "        print(f\"- {column}: {dtype}\")\n",
    "    \n",
    "    # NaN or missing values\n",
    "    missing_values = df.isnull().sum()\n",
    "    if missing_values.any():\n",
    "        print(\"\\nMissing Values in Each Column:\")\n",
    "        for column, missing_count in missing_values.items():\n",
    "            if missing_count > 0:\n",
    "                print(f\"- {column}: {missing_count} missing values\")\n",
    "    else:\n",
    "        print(\"\\nNo missing values found in the table.\")\n",
    "    \n",
    "    # Preview\n",
    "    print(\"\\nTable Preview (First 5 Rows):\")\n",
    "    print(df.head())\n",
    "\n",
    "def analyze_all_columns(file):\n",
    "    df = pd.read_csv(file)\n",
    "    \n",
    "    for column_name in df.columns:\n",
    "        print(f\"\\nAnalyzing column: '{column_name}'\")\n",
    "        \n",
    "        # Get unique values\n",
    "        unique_values = set(df[column_name].dropna())\n",
    "        unique_count = len(unique_values)\n",
    "        print(f\"Number of unique values: {unique_count}\")\n",
    "        print(f\"Unique values: {unique_values}\")\n",
    "\n",
    "        # Check if the column is numeric\n",
    "        if pd.api.types.is_float_dtype(df[column_name]):\n",
    "            # Calculate the range of values\n",
    "            min_value = df[column_name].min()\n",
    "            max_value = df[column_name].max()\n",
    "            value_range = max_value - min_value\n",
    "            \n",
    "            print(f\"\\nColumn '{column_name}' is of float type.\")\n",
    "            print(f\"Minimum value: {min_value}\")\n",
    "            print(f\"Maximum value: {max_value}\")\n",
    "            print(f\"Value range: {value_range}\")\n",
    "        else:\n",
    "            print(f\"Column '{column_name}' is not of float type.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file1 = \"../encoded data/opamps-features.csv\"\n",
    "analyze_csv_structure(file1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_all_columns(file1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file2 = \"../encoded data/opamps-xref.csv\"\n",
    "analyze_csv_structure(file2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_all_columns(file2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_rows_with_same_first_column(file):\n",
    "    # Find if two components has the same MPN id but different MPN name in table 1\n",
    "    df = pd.read_csv(file)\n",
    "    \n",
    "    duplicated_groups = df[df.duplicated(subset=df.columns[0], keep=False)]\n",
    "    \n",
    "    if duplicated_groups.empty:\n",
    "        print(\"No rows found with duplicate values in the first column.\")\n",
    "    else:\n",
    "        print(\"Rows with duplicate values in the first column:\")\n",
    "        print(duplicated_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_rows_with_same_first_column(file1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_matching_rows(file):\n",
    "    # Find if two components has the same MPN id but different MPN name\n",
    "    df = pd.read_csv(file)\n",
    "    \n",
    "    if df.shape[1] < 3:\n",
    "        print(\"The table must have at least three columns.\")\n",
    "        return\n",
    "\n",
    "    matching_rows = df[df.iloc[:, 0] == df.iloc[:, 2]]\n",
    "    \n",
    "    # Output\n",
    "    if matching_rows.empty:\n",
    "        print(\"No rows found where the values in the first and third columns match.\")\n",
    "    else:\n",
    "        print(\"Rows where the first and third column values match:\")\n",
    "        print(matching_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_matching_rows(file2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def analyze_npy_structure(file):\n",
    "    # Read the .npy file\n",
    "    data = np.load(file, allow_pickle=True)\n",
    "    \n",
    "    # Structure analysis\n",
    "    print(\"Data type:\", type(data))\n",
    "    print(\"Data shape:\", data.shape if hasattr(data, 'shape') else \"No shape attribute\")\n",
    "    print(\"Data dtype:\", data.dtype if hasattr(data, 'dtype') else \"No dtype attribute\")\n",
    "    \n",
    "    # Preview of data\n",
    "    if isinstance(data, np.ndarray):\n",
    "        print(\"\\nPreview of data (first 5 elements):\")\n",
    "        print(data[:5])\n",
    "    elif isinstance(data, (list, dict)):\n",
    "        print(\"\\nPreview of data (first few items):\")\n",
    "        for i, item in enumerate(data):\n",
    "            if i >= 5:\n",
    "                break\n",
    "            print(item)\n",
    "    else:\n",
    "        print(\"\\nData preview:\")\n",
    "        print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data type: <class 'numpy.ndarray'>\n",
      "Data shape: (18352, 18352)\n",
      "Data dtype: float64\n",
      "\n",
      "Preview of data (first 5 elements):\n",
      "[[0.9947077  0.9947077  0.4382915  ... 0.5984667  0.5984667  0.5984667 ]\n",
      " [0.9947077  0.9947077  0.39232178 ... 0.65109137 0.65109137 0.65109137]\n",
      " [0.4382915  0.39232178 0.9947077  ... 0.56951336 0.56951336 0.56951336]\n",
      " [0.4131604  0.41831909 0.40969788 ... 0.45082133 0.45082133 0.45082133]\n",
      " [0.60970538 0.40590678 0.38641846 ... 0.47005301 0.47005301 0.47005301]]\n"
     ]
    }
   ],
   "source": [
    "analyze_npy_structure('../results/opamps-scores-example.npy')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
